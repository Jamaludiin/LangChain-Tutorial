import os
from groq import Groq
from langchain_groq import ChatGroq
from langchain_core.messages.tool import default_tool_parser

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# Get Groq API key from environment variables
groq_api_key = os.getenv('GROQ_API_KEY')

# Initialize the Groq chat model
llm = ChatGroq(
    model="llama-3.3-70b-versatile",
    temperature=0.7,
    max_tokens=32767,
    timeout=10,
    max_retries=2,
)

# Sample raw tool call responses (some valid, some invalid)
raw_tool_calls = [
    {"name": "sum_numbers", "arguments": {"a": 5, "b": 10}},  # âœ… Valid
    {"name": "get_weather", "arguments": {"city": "New York"}},  # âœ… Valid
    {"wrong_key": "invalid_data"}  # âŒ Invalid
]

# Parse the tool calls using default_tool_parser
valid_calls, invalid_calls = default_tool_parser(raw_tool_calls)

# Print the results
print("âœ… Valid Tool Calls:")
for call in valid_calls:
    print(call)

print("\nâŒ Invalid Tool Calls:")
for call in invalid_calls:
    print(call)



"""
ğŸ”¹ Explanation
We define a list of tool calls (raw_tool_calls).
    Some are correctly structured (e.g., sum_numbers, get_weather).
    Some are incorrectly structured (wrong_key).
default_tool_parser processes the tool calls and returns:
    âœ… Valid tool calls (properly structured)
    âŒ Invalid tool calls (incorrectly structured)
We print the valid and invalid tool calls separately.


ğŸ”¹ Why Use This?
âœ… Automatically filters out incorrect tool calls
âœ… Helps AI handle API tool responses reliably
âœ… Avoids manual dictionary parsing

This is useful when working with AI agents that call external tools dynamically. ğŸš€
"""


"""
Difference Between default_tool_chunk_parser and default_tool_parser
Both methods process raw tool call data, but they have key differences in functionality and output.

1ï¸âƒ£ default_tool_chunk_parser
ğŸ“Œ Purpose:

Processes tool chunks (partial tool calls).
Returns a list of tool call chunks.
ğŸ“Œ Output:

list[ToolCallChunk] â†’ A list of processed tool call chunks.
âœ… Best when handling partial responses from AI models.

ğŸ”¹ Example Use Case:
If an AI model is streaming its output and hasn't completed a full tool call, this method helps extract whatever partial tool call is available.

2ï¸âƒ£ default_tool_parser
ğŸ“Œ Purpose:

Processes full tool calls.
Separates valid and invalid tool calls.
ğŸ“Œ Output:

tuple[list[ToolCall], list[InvalidToolCall]]
âœ… Valid tool calls (ToolCall)
âŒ Invalid tool calls (InvalidToolCall)
âœ… Best when handling complete tool call responses and filtering out bad tool calls.

ğŸ”¹ Example Use Case:
When an AI model generates multiple complete tool calls, this method helps separate good from bad before execution.

ğŸ” Summary: Key Differences
Feature	default_tool_chunk_parser	default_tool_parser
Processes	Partial tool call chunks	Full tool calls
Handles Streaming	âœ… Yes	âŒ No
Separates Valid & Invalid Calls	âŒ No	âœ… Yes
Best For	Handling AI responses that are incomplete	Filtering full tool call responses
ğŸš€ When to Use Which?
If working with partial tool call responses â†’ ğŸŸ¢ Use default_tool_chunk_parser
If working with complete tool call responses â†’ ğŸŸ¢ Use default_tool_parser

"""